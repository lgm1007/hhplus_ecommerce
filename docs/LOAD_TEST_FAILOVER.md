# 부하 테스트 및 가상 장애 대응 문서
## 부하 테스트
### 부하 테스트 대상 및 이유
주문 요청

**이유**: 주문 요청은 여러 사용자들이 접근할 수 있는 상품 재고라는 자원에 대한 요청이므로, 부하에 감당 가능해야 하는 기능이라고 판단했기 때문이다. 

### 부하 테스트 목적
주문 요청 API가 다양한 부하 조건에서 어떻게 동작하는지 평가하고, 시스템의 안정성, 응답 시간, 처리량 등을 확인한다. 이를 통해 시스템이 예상되는 트래픽을 처리할 수 있는지 확인하고, 장애가 발생하기 전에 병목 지점을 찾는 것이 목표이다.

#### 자세한 목표 설정

- **성능 한계 확인**: API가 처리할 수 있는 최대 요청 수 또는 동시 사용자 수를 파악
- **안정성 평가**: 서버가 일정 부하 이상에서 다운되지 않도록 하는 안정성 점검

### 부하 테스트 시나리오
부하 테스트 시나리오는 다양한 트래픽 패턴을 통해 API의 성능을 평가하는 것을 목표로 한다. 주문 요청 API는 실제 사용자 요청을 시뮬레이션하는 것이므로, 아래와 같은 시나리오를 고려할 수 있다.

- **정상 트래픽 시나리오**:
    - 하루 중 정상적인 시간대에 해당하는 트래픽 패턴을 시뮬레이션
    - 예시: 1초에 1건의 주문 요청
- **피크 트래픽 시나리오**:
    - 할인 행사나 특별 이벤트와 같은 특정 시점에 발생할 수 있는 높은 트래픽을 시뮬레이션
    - 예시: 1초에 100건 이상의 주문 요청이 몰리는 경우
- **부하 및 스트레스 테스트 시나리오**:
    - 시스템의 한계를 확인하기 위해 점진적으로 부하를 증가시켜 최대 트래픽을 시뮬레이션
    - 예시: 점차적으로 동시 사용자의 수를 증가시키고, 특정 임계값에서 장애가 발생하는지 확인

### 부하 테스트 스크립트
본 부하 테스트에서는 k6를 사용한다.

```javascript
import http from "k6/http";
import {check, sleep} from "k6";

export const options = {
    scenarios: {
        normal_traffic: {
            executor: 'constant-vus',
            vus: 10,  // 10명의 가상 사용자
            duration: "10s"  // 테스트 시간
        },
        peak_traffic: {
            executor: 'ramping-arrival-rate',  // 요청의 도달률 증가
            startRate: 50,  // timeUnit 당 50 번의 반복 속도로 테스트 진행
            timeUnit: '1s',
            preAllocatedVUs: 50,  // 테스트 진행 전에 50개의 가상 사용자 먼저 할당
            stages: [
                { duration: '10s', target: 500 },  // 10초 동안 timeUnit 당 500번의 반복
                { duration: '20s', target: 1000 },  // 20초 동안 timeUnit 당 1000번 반복 선형 증가
                { duration: '20s', target: 2000 },  // 40초 동안 timeUnit 당 2000번의 반복
                { duration: '10s', target: 0 },
            ],
        },
		stress_test: {
			executor: 'ramping-vus',  // 가상 사용자를 점진적으로 증가
			startVUs: 100,
			stages: [
				{ duration: '10s', target: 1000 },
				{ duration: '20s', target: 2000 },
				{ duration: '20s', target: 4000 },
				{ duration: '10s', target: 0 },
			],
		},
    },
};

export default function() {
    const url = 'http://localhost:8080/api/v1/orders'
    const payload = JSON.stringify({
        userId: 12345,
        orderItemInfos: [
            {
                productDetailId: 1,
                quantity: 1
            },
        ],
    });
    const params = {
        headers: {
            'Content-Type': 'application/json',
        },
    };
    const res = http.post(url, payload, params);
    check(res, {
        'is status 200': (r) => r.status === 200,
    });
    sleep(1);
}
```

### 부하 테스트 시나리오 별 성능 지표
#### k6 부하테스트 지표
K6 테스트에서 발생하는 지표는 다음과 같은 의미이다.

- **data_received**:
  - 서버로부터 수신된 데이터의 총량
- **data_sent**:
  - 클라이언트에서 서버로 보낸 데이터의 총량
- **http_req_blocked**:
  - 요청이 네트워크에서 차단된 시간. 예를 들어, DNS 조회나 연결 대기와 같은 초기 네트워크 지연 시간 포함
- **http_req_connecting**:
  - 서버와 연결을 설정하는 데 걸린 시간. 네트워크 지연이나 DNS 문제 등으로 인해 병목이 발생할 수 있는 부분.
- **http_req_duration**:
  - 한 HTTP 요청의 전체 지속 시간. `(http_req_connecting + waiting + receiving)`
- **http_req_failed**:
  - 실패한 HTTP 요청의 비율.
- **http_req_receiving**:
  - 응답 데이터를 클라이언트가 수신하는 데 걸린 시간.
- **http_req_sending**:
  - 요청 본문을 서버에 전송하는 데 걸린 시간.
- **http_req_waiting**:
  - 서버로 요청을 보낸 후 응답을 기다리는 시간. 백엔드 처리 시간과 유사하며, API 성능의 핵심 지표
- **http_reqs**:
  - 요청 수를 측정. 부하 테스트를 통해 얼마나 많은 HTTP 요청이 발생했는지 확인할 수 있다.
- **iteration_duration**:
  - 각 반복(iteration)이 완료되는데 걸리는 시간.
- **vus**:
  - 실행 중인 가상 사용자의 수

**성능 지표로 병목 탐색하기:**

- **HTTP 요청 실패율 (http_req_failed)**
  - **병목 현상**: 만약 요청 실패율이 급격히 증가한다면, 서버가 요청을 제대로 처리하지 못하고 있다는 신호이다. 이는 서버의 **자원 부족**이나 **코드 오류**, **네트워크 문제** 등으로 인해 발생할 수 있다.
  - **탐색 방법**: 요청 실패율이 높다면, 서버 로그나 인프라 상태를 점검해보고, 리소스가 과부하 상태인지, 시스템 구성에 문제가 있는지를 확인해야 한다.
- **응답 시간 (http_req_duration)**
  - **병목 현상**: 응답 시간이 너무 길다면, 이는 **서버의 처리 능력** 또는 **데이터베이스 쿼리**, **네트워크 지연** 등의 병목을 나타낼 수 있다. 응답 시간이 너무 길면 사용자는 불만을 가질 수 있으며, 시스템의 확장성을 고려해야 한다.
  - **탐색 방법**: 평균 응답 시간, 95백분위수, 최대 응답 시간 등을 분석하여 성능 문제를 구체적으로 파악한다. 예를 들어, **95th percentile**(95백분위수)을 기준으로 응답 시간이 급격히 늘어난다면, 특정 요청이 시스템을 과부하시키는 경우일 수 있다.
- **네트워크 연결 시간 (http_req_connecting)**
  - **병목 현상**: `http_req_connecting` 시간이 길면 네트워크 연결에서 병목이 발생하고 있음을 나타낸다. 이는 DNS 해결 문제, 서버와의 연결 지연, 네트워크 구성 오류 등이 원인일 수 있다.
  - **탐색 방법**: 연결 시간 자체가 길다면 서버의 네트워크 환경을 점검하고, 클라이언트와 서버 간의 물리적 거리가 너무 멀어지지 않았는지, DNS 서비스가 적절히 작동하는지 등을 확인할 필요가 있다.
- **대기 시간 (http_req_waiting)**
  - **병목 현상**: 대기 시간이 길다면, 이는 서버가 요청을 처리하는 데 시간이 걸리고 있다는 신호이다. 이는 **서버의 CPU/메모리 자원 부족**, **DB 쿼리 성능 문제**, **서버의 병목 지점** 등에서 발생할 수 있다.
  - **탐색 방법**: 대기 시간이 길다면 서버의 리소스 사용률을 확인하고, DB 쿼리 성능을 튜닝하거나 서버의 성능을 확장할 필요가 있다. 예를 들어, 특정 API나 데이터베이스가 병목이 될 수 있다.
- **처리된 초당 요청 수 (throughput)**
  - **병목 현상**: 처리할 수 있는 초당 요청 수가 줄어들면 서버의 처리 성능이 한계에 도달한 상태일 수 있다. 이는 서버 자원이 부족하거나 시스템 아키텍처가 최적화되지 않았을 때 발생할 수 있다.
  - **탐색 방법**: `throughput`이 예상보다 적다면, 서버의 **CPU**, **메모리**, **네트워크 대역폭** 등을 점검하여 병목이 있는 지점을 파악한다. 특히 리소스 사용률을 모니터링하여 성능을 개선할 수 있다.
- **가상 사용자 수 (vus)**
  - **병목 현상**: 가상 사용자 수가 급격히 증가하면서 성능 저하가 발생한다면, 이는 **서버의 동시 처리 능력** 또는 **리소스 한계**를 나타낸다.
  - **탐색 방법**: 가상 사용자 수가 많을 때 시스템 성능이 저하된다면, 서버의 **동시성 처리 능력**이나 **애플리케이션 아키텍처**에 문제가 있을 수 있다. 예를 들어, 애플리케이션에서 병렬 처리나 캐싱 전략을 최적화할 필요가 있다.
- **에러율 (error_rate)**
  - **병목 현상**: 에러율이 높아진다면 시스템이 과부하를 일으키고 있거나 코드 수준에서 문제가 있을 수 있다. 이는 서버가 처리할 수 있는 요청 수를 초과하거나 잘못된 요청을 받았을 때 발생할 수 있다.
  - **탐색 방법**: 에러율이 높다면, 시스템의 로깅 기능을 활용하여 실패한 요청에 대한 원인 분석을 해야 한다. 예를 들어, 코드 오류, 잘못된 API 호출, 잘못된 파라미터 등이 원인일 수 있다.

##### 1. 정상 트래픽 시나리오

![normal_traffic_k6_log](https://github.com/user-attachments/assets/db9a3abb-8df9-490b-893e-bf82f661fa2e)
![normal_traffic_k6](https://github.com/user-attachments/assets/ab4251b7-cb02-4450-af65-245d080d662d)

- **data_received**: 55 KB
- **data_sent**: 22 KB
- **http_req_blocked**:
  - avg: 190.32 us
  - p(90): 554.13 us
  - p(95): 2 ms
  - max: 2 ms
- **http_req_connecting**: 
  - avg: 99.99 us
  - p(90): 99.99 us
  - p(95): 999.9 us
  - max: 999.9 us
- **http_req_duration**:
  - avg: 5.13 ms
  - p(90): 8.08 ms
  - p(95): 9.13 ms
  - max: 11.47 ms
- **http_req_failed**: 0.0 %
- **http_req_receiving**:
  - avg: 141.4 us
  - p(90): 513.62 us
  - p(95): 524.42 us
  - max: 1.02 ms
- **http_req_sending**:
  - avg: 2.81 us
  - p(90): 0 s
  - p(95): 0 s
  - max: 281.7 us
- **http_req_waiting**:
  - avg: 4.98 ms
  - p(90): 8.08 ms
  - p(95): 9.13 ms
  - max: 11.47 ms
- **http_reqs**: 100,  9.895/s
- **iteration_duration**:
  - avg: 1 s
  - p(90): 1.01 s
  - p(95): 1.01 s
  - max: 1.02 s
- **vus**: 10

##### 2. 피크 트래픽 시나리오

![peak_traffic_k6_log](https://github.com/user-attachments/assets/3d96d9b2-96ad-4361-bb82-0c00aadd780d)
![peak_traffic_k6](https://github.com/user-attachments/assets/81b92ea8-5bc8-4a49-9d0e-eeff1efa800b)

- **data_received**: 1.6 MB
- **data_sent**: 638 KB
- **http_req_blocked**:
  - avg: 15.23 us (정상 트래픽 대비 -175.09 us)
  - p(90): 0 s
  - p(95): 0 s
  - max: 2.83 ms (+0.83 ms)
- **http_req_connecting**:
  - avg: 10.95 us (-89.04 us)
  - p(90): 0 s (-99.99 us)
  - p(95): 0 s (-999.9 us)
  - max: 2.08 ms (+1.07 ms)
- **http_req_duration**:
  - avg: 4.59 ms (-0.54 ms)
  - p(90): 9.56 ms (+1.48 ms)
  - p(95): 13.21 ms (+4.08 ms)
  - max: 55.4 ms (+43.93 ms)
- **http_req_failed**: 0.0 %
- **http_req_receiving**:
  - avg: 181.51 us (+40.11 us)
  - p(90): 604.97 us (+91.35 us)
  - p(95): 965.79 us (+441.37 us)
  - max: 6.28 ms (+5.26 ms)
- **http_req_sending**:
  - avg: 16.06 us (+13.25 us)
  - p(90): 0 s
  - p(95): 0 s
  - max: 1.02 us (-280.68 us)
- **http_req_waiting**:
  - avg: 4.39 ms (-0.59 ms)
  - p(90): 9.08 ms (+1 ms)
  - p(95): 12.98 ms (+3.85 ms)
  - max: 54.81 ms (+43.34 ms)
- **http_reqs**: 2952,  48.386/s
- **iteration_duration**:
  - avg: 1 s
  - p(90): 1.01 s
  - p(95): 1.02 s (+0.01 s)
  - max: 1.06 s (+0.04 s)
- **vus**: 50

##### 3. 부하 및 스트레스 테스트 시나리오

![load_test_k6_log](https://github.com/user-attachments/assets/70820339-942f-431f-bc16-7c032159986a)
![load_test_k6](https://github.com/user-attachments/assets/383dc483-393a-4d1a-b605-e701982f00a6)

- **data_received**: 40 MB
- **data_sent**: 16 MB
- **http_req_blocked**:
  - avg: 60.59 us (정상 트래픽 대비 -129.73 us)
  - p(90): 0 s
  - p(95): 518.59 us (-1.48 ms)
  - max: 5.53 ms (+3.53 ms)
- **http_req_connecting**:
  - avg: 53.76 us (-46.23 us)
  - p(90): 0 s
  - p(95): 513.2 us (-486.7 us)
  - max: 5.53 ms (+4.53 ms)
- **http_req_duration**:
  - avg: 663.94 ms (+658.81 ms)
  - p(90): 1.65 s (+1.64 s)
  - p(95): 1.71 s (+1.7 s)
  - max: 3.08 s (+3.07 s)
- **http_req_failed**: 0.0 %
- **http_req_receiving**:
  - avg: 111.32 us (-30.08 us)
  - p(90): 517.1 us (+3.48 us)
  - p(95): 525.2 us (+0.78 us)
  - max: 7.33 ms (+6.31 ms)
- **http_req_sending**:
  - avg: 12.69 us (+9.88 us)
  - p(90): 0 s
  - p(95): 0 s
  - max: 41.01 ms (+40.7 ms)
- **http_req_waiting**:
  - avg: 663.81 ms (+658.83 ms)
  - p(90): 1.65 s (+1.64 s)
  - p(95): 1.71 s (+1.7 s)
  - max: 3.07 s (+3.06 s)
- **http_reqs**: 71553,  1177.624/s
- **iteration_duration**:
  - avg: 1.66 s (+0.66 s)
  - p(90): 2.65 s (+1.64 s)
  - p(95): 2.71 s (+1.7 s)
  - max: 4.08 s (+3.06 s)
- **vus**:
  - min: 189
  - max: 3999

#### JVM Monitor 지표
##### 1. 정상 트래픽 시나리오

![normal_traffic_grafana](https://github.com/user-attachments/assets/ed39ee5e-584f-4d08-8b8c-a90754b53910)


##### 2. 피크 트래픽 시나리오

![peak_traffic_grafana](https://github.com/user-attachments/assets/bb7ba1b5-3b55-49a4-8edb-9b5f780a4757)


##### 3. 부하 및 스트레스 테스트 시나리오

![stress_test_grafana](https://github.com/user-attachments/assets/0a7350cd-70c5-4310-9bdf-b5819f98cd01)

## 가상 장애 시나리오
**장애 상황**:

주문 요청 API의 서버가 갑작스럽게 응답을 하지 않거나, 응답 시간이 급증하는 문제가 발생. 트래픽이 급증하면서 시스템이 처리할 수 있는 한계를 초과했으며, 이로 인해 API 응답 지연 및 에러가 발생하고 있습니다. 시스템에서 "500 Internal Server Error"가 다수 발생하는 상황입니다.

### 장애 대응 문서
#### 1. 장애 개요

- **장애 발생 시간**: 2024년 11월 25일 오전 10:15
- **장애 발생 원인**:
  - 갑작스러운 주문 요청 수의 급증(피크 트래픽)으로 인해 서버의 CPU 및 메모리 사용량이 한계에 도달
  - 데이터베이스 쿼리의 비효율적인 처리로 인해 API 응답 시간이 급증
  - 네트워크 대역폭 부족으로 인한 데이터 전송 지연
  - 서버 리소스의 스케일링 부족으로 인한 트래픽 처리 불가

#### 2. 장애 영향

- **주요 장애 증상**:
  - 주문 API 응답 시간 급증 (평균 응답 시간 1초에서 5초 이상으로 증가)
  - "500 Internal Server Error"가 30% 이상의 요청에서 발생
  - 일부 사용자에게 주문이 실패하거나, 주문 상태가 정확하게 반영되지 않음
- **영향을 받은 시스템**:
  - 주문 요청 API 서버
  - 데이터베이스 서버 (특히 쿼리 처리 속도 저하)
  - 네트워크 대역폭 (응답 지연 및 데이터 전송 오류 발생)

#### 3. 장애 대응 절차
##### 3.1 장애 발생 직후

- **1단계: 시스템 모니터링** (예상 소요시간: 5분 이내)
  - CPU, 메모리, 네트워크 사용량을 실시간으로 확인하여 리소스 사용량이 한계에 도달했는지 확인
  - 서버 로그에서 "500 Internal Server Error"가 발생한 시간대의 로그를 확인하여 문제가 발생한 지점을 파악
  - 데이터베이스 쿼리 처리 시간을 분석하여 병목이 발생한 쿼리를 식별
- **2단계: 트래픽 분석** (예상 소요시간: 10분 이내)
  - K6 부하 테스트에서 발생한 트래픽 패턴을 확인하고, 예상보다 높은 트래픽이 유입되었는지 점검
  - 트래픽을 분산시키기 위해 로드 밸런서를 점검하고, 필요시 트래픽 분산 비율을 재조정
- **3단계: 리소스 확장** (예상 소요시간: 20분 이내)
  - 자동 스케일링 기능을 확인하고, 서버 인스턴스를 수동으로 추가하여 리소스를 확장
  - 네트워크 대역폭을 확인하고, 필요시 대역폭을 확장하여 병목을 해소

##### 3.2 장애 복구 작업

- **1단계: 서버 재시작** (예상 소요시간: 30분 이내)
  - API 서버 및 데이터베이스 서버를 순차적으로 재시작하여 초기화 후, 시스템 리소스 확보
  - 캐시 시스템을 초기화하여 잘못된 데이터가 시스템에 남지 않도록 처리
- **2단계: API 최적화** (예상 소요시간: 2~3시간 이내)
  - 데이터베이스 쿼리 성능을 최적화 (예: 인덱스 추가, 쿼리 리팩토링 등)
  - API 응답 시간을 최적화하여 평균 응답 시간이 2초 이하로 복귀할 수 있도록 조치
  - 서버의 로깅 및 모니터링 시스템을 강화하여 향후 비슷한 상황에 빠르게 대응할 수 있도록 개선
- **3단계: 트래픽 안정화** (예상 소요시간: 1시간 이내)
  - 트래픽을 일정한 수준으로 분산시키기 위해 로드 밸런서의 설정을 조정
  - 예상되는 트래픽 변화에 대비하여 미리 부하 분산 전략을 설정하고, 급증할 수 있는 상황에 대비

##### 3.3 모니터링 강화

- **1단계: 실시간 모니터링**
  - 장애 발생 원인 분석 후, 실시간 모니터링 툴(예: Prometheus, Grafana)을 사용하여 시스템 상태를 지속적으로 모니터링
  - CPU, 메모리, 네트워크 등 시스템 리소스를 실시간으로 감시하고, 임계값을 설정하여 자동으로 알림을 받을 수 있도록 설정
- **2단계: 로깅 시스템 강화**
  - 장애 발생 당시의 로그 분석을 통해 문제가 발생한 API 또는 데이터베이스 쿼리를 추적
  - 향후 비슷한 장애가 발생할 경우 빠르게 대응할 수 있도록 로그 데이터를 체계적으로 저장하고 분석할 수 있는 시스템 개선

#### 4. 재발 방지 대책

- **숏텀 (1~2개월 이내)**
  - 리소스 확장 및 최적화
    - 서버 자동 스케일링을 즉시 활성화하고 트래픽 급증에 빠르게 대응할 수 있도록 설정
    - 데이터베이스 인덱스를 추가하고 쿼리 성능 분석하여 개선 작업 수행
    - 네트워크 대역폭을 일시적으로 확대하여 현재 트래픽 수준에서 발생하는 지연 해결
  - 단기 부하 테스트 진행
    - 예상되는 최대 트래픽을 기반으로 K6 등을 사용한 부하 테스트를 강화하여 서버의 한계 미리 파악
    - 비정상적인 트래픽 패턴에 대한 부하 테스트 진행 및 대응
- **미드텀 (3~6개월 이내)**
  - 성능 최적화
    - 데이터베이스 쿼리 리팩토링 및 캐시 시스템 도입을 통해 쿼리 성능을 지속적으로 개선
    - API 응답 최적화를 위한 로직 리팩토링 및 분산 시스템 도입 검토
    - 로드 밸런서 설정 최적화: 트래픽 분산 기능을 최적화하여 서버의 부하를 분산시키고, 비정상적인 트래픽의 영향 최소화
  - 부하 분산 전략 개선
    - 트래픽 패턴을 분석하여 피크 시간대에 맞춘 부하 분산 전략을 마련하고, 예상치 못한 급증에 대비한 트래픽 관리 계획 수립
    - 필요 시 서버의 지리적 분산을 통해 글로벌 트래픽을 효율적으로 관리
- **롱텀 (6개월 이상)**
  - 시스템 리소스 확장
    - 고가용성 아키텍처 구축: 멀티 리전 및 멀티 존 기반의 고가용성 아키텍처를 구축하여 시스템 장애 발생 시 복구 시간 최소화
    - 서버 성능 분석 및 확장: 서버 및 데이터베이스 성능을 지속적으로 분석하고, 트래픽에 맞춰 리소스를 탄력적으로 확장할 수 있는 시스템 구축
  - 전사적 장애 대응 매뉴얼 및 교육 강화
    - 장애 대응 매뉴얼을 주기적으로 검토하고, 팀원들 간의 대응 훈련을 강화하여 모든 팀원이 신속하고 일관되게 대응할 수 있도록 교육
    - AI 기반의 예측 시스템 도입 검토: 트래픽 패턴을 예측하고, 사전에 대응할 수 있는 시스템을 구축하여 사전에 장애 예방

#### 5. 장애 후 분석

- **장애 발생 원인**:
  - 급증한 트래픽에 대비하지 못한 서버 리소스 부족과, 비효율적인 데이터베이스 쿼리로 인해 응답 시간이 급증하며 장애 발생.
- **재발 방지 조치**:
  - 서버 리소스를 적절히 확장하고, 쿼리 성능을 최적화하는 등 성능 개선 작업을 수행
  - 부하 테스트를 통해 시스템의 한계를 명확히 파악하고, 장애 발생 가능성 있는 부분을 사전 예방
  - 재발 방지 대책을 미드텀, 롱텀 시간 기준으로 수립
